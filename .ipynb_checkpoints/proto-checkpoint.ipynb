{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir, path\n",
    "import datetime\n",
    "import pydoc\n",
    "import time\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "def assemble(wikiname):\n",
    "    \"\"\"\n",
    "    assemble the html given a wikiname\n",
    "    \"\"\"\n",
    "    content = vimwikihtml2content(wikiname)\n",
    "    template = open('default.tpl', 'r')\n",
    "    data = template.read()\n",
    "    data = data.replace('%title%', gettitle(wikiname))\n",
    "    data = data.replace('%title%', gettitle(wikiname))\n",
    "    data = data.replace('%index%', navbar(wikiname))\n",
    "    data = data.replace('%content%',content)\n",
    "    data = data.replace('%date%', getdate(wikiname))\n",
    "    htmlname = wikiname + '.html'\n",
    "    htmlfile = open('../html/' + htmlname, 'w')\n",
    "    htmlfile.write(data)\n",
    "    #return data\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "def getnamelist():\n",
    "    \"\"\"\n",
    "    return the list of wikinames\n",
    "    \"\"\"\n",
    "    namelistfile = open('wikilist', 'r')\n",
    "    namelist = []\n",
    "    while True:\n",
    "        name = namelistfile.readline().replace('\\n', '')\n",
    "        if name == '':\n",
    "            break\n",
    "        else:\n",
    "            namelist += [name]\n",
    "    return namelist\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "def assembleall():\n",
    "    \"\"\"\n",
    "    assemble all html pages in the namelist\n",
    "    \"\"\"\n",
    "    namelist = getnamelist()\n",
    "    for name in namelist:\n",
    "        assemble(name)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def vimwikihtml2content(wikiname):\n",
    "    \"\"\"\n",
    "    truncate the html converted from wiki using vimwiki to the portion fit in %content% in the template\n",
    "    \"\"\"\n",
    "    htmlname = '../wiki_html/' + wikiname + '.html'\n",
    "    html = open(htmlname, 'r')\n",
    "    data = html.read()\n",
    "    pos1 = data.find('<body>')\n",
    "    pos2 = data.find('</body>')\n",
    "    data = data[pos1 + 6 : pos2]\n",
    "    return data\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "def navbar(wikiname):\n",
    "    \"\"\"\n",
    "    assemble the left navbar of wikiname.html\n",
    "    \"\"\"\n",
    "    listfile = open('wikilist', 'r')\n",
    "    data = ''\n",
    "    data += '<ul>'\n",
    "    while True:\n",
    "        n = listfile.readline().replace('\\n', '')\n",
    "        if n == '':\n",
    "            break\n",
    "        t = gettitle(n)\n",
    "        if n != wikiname:\n",
    "            data += '<li><a href=\"' + n + '.html\">' + t + '</a></li>'\n",
    "        else:\n",
    "            data += '<li>' + t + '</li>'\n",
    "    data += '</ul>'\n",
    "    return data\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "def gettitle(wikiname):\n",
    "    \"\"\"\n",
    "    parse the title of wikiname.wiki.\n",
    "    If %title field exists then use it, otherwise use wikiname\n",
    "    \"\"\"\n",
    "    wikifile = open('../wiki/' + wikiname + '.wiki', 'r')\n",
    "    data = wikifile.read()\n",
    "    pos = data.find('%title')\n",
    "    if pos == -1:\n",
    "        return wikiname\n",
    "    pos += 7\n",
    "    pos1 = data.find('\\n', pos)\n",
    "    rawtitle = data[pos: pos1]\n",
    "    nd = rawtitle.count('$')\n",
    "    title = ''\n",
    "    for i in range(int(nd /  2)):\n",
    "        fd = rawtitle.find('$')\n",
    "        sd = rawtitle.find('$', fd + 1)\n",
    "        title += rawtitle[ : fd] + '\\(' + rawtitle[fd + 1 : sd] + '\\)'\n",
    "        rawtitle = rawtitle[sd + 1:]\n",
    "    title += rawtitle\n",
    "    return title\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "def getdate(wikiname):\n",
    "    \"\"\"\n",
    "    get the modification date of wikiname.wiki\n",
    "    \"\"\"\n",
    "    ct = time.ctime(path.getmtime('../wiki/' + wikiname + '.wiki'))\n",
    "    tt = ct.split()\n",
    "    return tt[2] + ' ' + tt[1] + ' ' + tt[-1]\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "def genlist():\n",
    "    \"\"\"\n",
    "    generate a list of the wikinames, namely find all .wiki files and put their file names (without .wiki extension) in \n",
    "    a file\n",
    "    \"\"\"\n",
    "    flist = [f for f in listdir('../wiki') if f[-5:] == '.wiki']\n",
    "    namelist = [f[:-5] for f in flist]\n",
    "    namelist.sort()\n",
    "    #titlelist = [gettitle(name) for name in namelist]\n",
    "    outfile = open('wikilist', 'w')\n",
    "    for n in namelist:\n",
    "        outfile.write(n + '\\n')\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "def removebrokenlinks(html):\n",
    "    ap1 = html.find('<a href')\n",
    "    result = html[: ap1]\n",
    "    while ap1 != -1:\n",
    "        ap2 = html.find('>', ap1)\n",
    "        ap3 = html.find('</a>', ap2)\n",
    "        ap4 = ap3 + 4\n",
    "        linkp1 = html.find('\"', ap1 + 1)\n",
    "        linkp2 = html.find('\"', linkp1 + 1)\n",
    "        link = '../wiki/' + html[linkp1 + 1 : linkp2 - 5] + '.wiki'\n",
    "        if not path.isfile(link):\n",
    "            delta = html[ap2 + 1 : ap3]\n",
    "        else:\n",
    "            delta = html[ap1 : ap4]\n",
    "        ap1 = html.find('<a href', ap4)\n",
    "        result += delta + html[ap4 : ap1]\n",
    "    result += html[-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removebrokenlinks(html):\n",
    "    ap1 = html.find('<a href')\n",
    "    result = html[: ap1]\n",
    "    while ap1 != -1:\n",
    "        ap2 = html.find('>', ap1)\n",
    "        ap3 = html.find('</a>', ap2)\n",
    "        ap4 = ap3 + 4\n",
    "        linkp1 = html.find('\"', ap1 + 1)\n",
    "        linkp2 = html.find('\"', linkp1 + 1)\n",
    "        link = '../wiki/' + html[linkp1 + 1 : linkp2 - 5] + '.wiki'\n",
    "        if not path.isfile(link):\n",
    "            delta = html[ap2 + 1 : ap3]\n",
    "        else:\n",
    "            delta = html[ap1 : ap4]\n",
    "        ap1 = html.find('<a href', ap4)\n",
    "        result += delta + html[ap4 : ap1]\n",
    "    result += html[-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str.find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p> <span id=\"-Claim\"></span><strong id=\"Claim\">Claim</strong>. For \\\\(\\theta &gt; 0\\\\), if \\\\(X_n \\\\sim Geom(\\theta / n)\\\\) then \\\\(X_n / n \\\\leadsto Exp(\\theta)\\\\) the exponential distribution with parameter \\\\(\\theta\\\\). Write this as \\\\(Geom(\\theta / n) / n \\to Exp(\\theta)\\\\). </p>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '<p> <span id=\"-Claim\"></span><strong id=\"Claim\">Claim</strong>. For \\(\\theta &gt; 0\\), if \\(X_n \\sim Geom(\\theta / n)\\) then \\(X_n / n \\leadsto Exp(\\theta)\\) the <a href=\"exponential_distribution.html\">exponential distribution</a> with parameter \\(\\theta\\). Write this as \\(Geom(\\theta / n) / n \\to Exp(\\theta)\\). </p>'\n",
    "removebrokenlinks(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p> It is a probability distribution due to Cauchys \\\\(q\\\\)-binomial series formula, (3) in <a href=\"q_analogs.html\">q_analogs</a>. </p>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '<p> It is a probability distribution due to Cauchys \\(q\\)-binomial series formula, (3) in <a href=\"q_analogs.html\">q_analogs</a>. </p>'\n",
    "removebrokenlinks(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doob's $h$-transform\n",
      "7 9 Doob's \\(h\\)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Doob's \\\\(h\\\\)-transform\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettitle('doob_transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genlist()\n",
    "assembleall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\(\\)\n"
     ]
    }
   ],
   "source": [
    "a = 'oaiwefoi$o iwjefoijweio$ woeijfiowej$'\n",
    "a.count('$')\n",
    "print('\\(\\)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path.getmtime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path.isfile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
